---
title: A toy demonstration of the Profiled Feldman-Cousins Technique
format: gfm

execute:
  echo: false
  warning: false
---

```{r}
library(tidyverse)
library(latex2exp)
library(scales)
```

This repository contains code to demonstrate the algorithms used in the "Profiled Feldman-Cousins" technique for parameter and confidence interval estimation.
It is a *toy* demonstration in that the physical model used is not motivated by any physics, and is very simple.
The actual problems to which this technique is applied are much more complicated.
The entire well-motivated and more more complex physical models, and many more parameters.

## The toy physical model

Our toy physical model contains to major propositions:

1.  The process we are observing (the appearance of events with energy $x$ in our detector) is a Poisson process.
    This means the observed energy spectrum (the count of events in each energy bin) is an observation of a $N_b$ independent Poisson random variables, where $N_b$ is the number of bins in our spectrum.

2.  The Poisson mean $\mu_k$ for each bin $k$ (will will use $k$ to index energy bins) is: $$\mu_k = A e^{(-k/B)} + \frac{C}{\Delta} e^{-\frac{1}{2} (\frac{k-m}{\Delta})^2} + D$$

    $A$, $B$, $C$, $D$, $m$ and $\Delta$ each denote scalar values.
    We are interested in the parameters $m$ and $\Delta$; these are the parameters we are estimating.
    The parameters $A$, $B$, $C$ and $D$ are nuisance parameters; they play a role in the "physics", but we do not care about their values.

This means that the likelihood that we are maximizing is: $${\cal L} = \prod\limits_{k=1}^{N_b} P(d_k | \mu_k)$$ where $P(d_k | \mu_k)$ is the likelihood for observing $d_k$ events in a Poisson process with mean $\mu_k$: $$P(d|\mu) = e^{-\mu} \mu^d / d!$$

In the real neutrino experiments, the formula for $\mu_k$ is much more complicated, and the likelihood has additional multiplicative terms.
But the toy shared the essential feature that the likelihood for the observed data depends upon the unknown values of the parameters, both the interesting ones and the nuisance parameters.

Because individual likelihoods can be quite small, it is common to work with the natural logarithm of the likelihood.
The likelihood has a maximum where the log of the likelihood has a maximum.
Finally, we usually work with the *negative* of the log of the likelihood.
The finding of the maximum likelihood corresponds to minimization of the negative log likelihood.

Some physicists like working with the value defined as if we were working with a Gaussian likelihood, in which case the log of the likelihood would be the $\chi^2$ function.
The typical definition of the $\chi^2$ function contains a factor of two in the log.
The definition of $\lambda$ follows this tradition:

$$
\begin{aligned}
\lambda(A, B, C, D, m, \Delta) &= -2 \log({\cal L}) \\
                               &= 2 \sum\limits_{k=1}^{N_b} ( \mu_k - d_k \log(\mu_k) + \log(d_k!)  )
\end{aligned}
$$

Sometimes, Stirling's approximation for $d_k!$ is introduced here, since it is already quite accurate for $n=1$.
The code in this repository does *not* make this approximation.

Note that $\lambda$ above is a function of the parameters of the model ($A$, $B$, $C$, $D$, $m$, and $\Delta$); these are the variables being fitted.
It is not a function of the data $\vec{d}$, which are not varied --- the data are whatever the experiment observed.
The dependence of $\lambda$ on these parameters comes in through the dependence of each $\mu_k$ on these parameters.

### Creating simulated data

Since we have not run a real physical experiment to collect data that we can fit out our model, we need to generate some.
This process is similar (but not identical) to the process we'll use for generating pseudoexperiments.
Note that this step is *not* part of the profiled FC technique; it is something we have to do because we did not actually perform an experiment to collect data.

First we need to specify the *true* values for the model parameters.
In the real world, we do not know the true values of the model parameters.
But because we are making a simulation, in our simulated world we get to set the values.
Note that this implies the proposition that our model is a faithful model of physical reality.
For the simulated reality, this is true.
In the real world, we do not know this is true.
But in the profiled FC analysis, we are not *testing* that proposition.
We are asserting the proposition, and then given that assertion, we are estimating the values of the parameters of interest of the model.

```{r}
A <- 10.2
B <- 5.3
C = 3.5
D = 0.7
m = 8.3
Delta = 1.8
params <- tibble(name = c("A", "B", "C", "D", "m", "Delta"),
                 value = c(A, B, C, D, m, Delta))
```

```{r}
#| label: tbl-param-truth
#| tbl-cap: The true values for all the parameters in our model.
#| tbl-cap-location: top
knitr::kable(params)
```

```{r}
N_b <- 20 # Number of bins in spectrum
mu_k <- function(k) A * exp(-k/B) + (C/Delta) * exp(-0.5 * ((k-m)/Delta)**2) + D
means <- tibble(k = 1:N_b,
               mu = mu_k(1:N_b))
```

This set of parameters yields the following expected "shape" for the spectrum.
Note that this is a plot of the Poisson mean for each bin, not the number of observed events in the simulated experiment (that we have not yet simulated).

```{r spectrum}
#| label: fig-true-mean
#| fig-cap: True Poisson mean as a function of energy bin index

ggplot(means, aes(k, mu)) +
  geom_point() +
  scale_y_log10() +
  labs(x = "bin index", y = TeX("$\\mu$"))
```

```{r}
set.seed(127)
observations <- sapply(means$mu, function(x){rpois(1, x)})
data <- tibble(bin = 1:N_b,
               n = observations)
write_csv(data, "spectrum.csv")
```

Finally, we generate $N_b$ Poisson random variates: the energy spectrum of our simulated data.
Our (simulated) spectrum is: `r data$n`.

```{r observed_spectrum}
#| label: fig-observed-spectrum
#| fig-cap: Observed spectrum (for our simulated experiment).

ggplot(data, aes(bin, n)) +
    geom_point() +
    scale_y_continuous(breaks = pretty_breaks()) +
    labs(x = "bin index", y = "Observed number of events")
```

## Profiling over nuisance parameters

When we perform a physics experiment, we do not know the true values of the model parameters we are estimating.
We sometimes have information about at least some of the parameters.
Often this information takes the form of estimated values and uncertainties for those parameters.
In this case, we will assume we have such information --- from some other source, not from our experiment --- for all our nuisance parameters.
We will assume the following values and uncertainties when we are doing the profiling over the nuisance parameters.

```{r}
set.seed(1337)
nuisance_params <-
    tibble(name = c("A", "B", "C", "D"),
           sd = c(0.3, 0.1, 0.6, 0.04))
# The first 4 rows in "params" are our nuisance parameters
deviations <- rnorm(4) #  means 0, sds=1
nuisance_params$mean <- round(params[1:4,]$value + deviations*nuisance_params$sd, 2)
nuisance_params <- relocate(nuisance_params, mean, .after = name)
write_csv(nuisance_params, "nuisance.csv")
```

```{r}
knitr::kable(nuisance_params)
```

## The Profiled Feldman-Cousins calculation
